# -*- coding: utf-8 -*-
"""Solar Wind GRBM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y67dYmihDd2p8QZg7fMVd2cdm3G66NH3
"""

"""# Data Loading

## Loading Data
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from tqdm import tqdm 
import torch
# %matplotlib inline
plt.style.use('ggplot')
plt.switch_backend('agg')

# To try using gpu
def try_gpu(i=0):
    """Return gpu(i) if exists, otherwise return cpu()."""
    if torch.cuda.device_count() >= i + 1:
        return torch.device(f'cuda:{i}')
    return torch.device('cpu')
# Device can also be GPU
# device = torch.device("cpu")
device = try_gpu()
# Empty memory of GPU
# torch.cuda.empty_cache()
# Load the data 
# If hourly write 1 if six hours write 6
data_rate = 6
days_solar_cycle = 27*2
# This is the shift in the indexes of the database to select the samples
index_shift = int(days_solar_cycle*24/data_rate)

if data_rate == 1:
    df = pd.read_csv('/content/gdrive/My Drive/LRI Stage/Processed_databases/Db_Sun_2010_2020_hourly.csv', index_col=0)
if data_rate == 6:
    df_train = np.load('Real_train_54d_1999_2020_3_quarters.npy')
    df_test = np.load('Real_test_54d_1999_2020_3_quarters.npy')
# Data taken from PLASMA: WIND HOURLY previously preprocessed
# Center the data
train_mean = df_train.mean()
train_data_std = df_train.std()
df_train -= train_mean
df_train /= train_data_std
df_test -= train_mean
df_test /= train_data_std

'''
# Visualizing the samples
x_plot = np.arange(0, days_solar_cycle, data_rate/24)
plot_int = np.random.randint(df_train.shape[0])
n_step_plots = 6
plt.figure(figsize=(10,6))
for plot, sample in enumerate(range(plot_int, plot_int+n_step_plots)):
    plt.plot(x_plot, df_train[sample]+(plot*4))
plt.yticks([])
'''
# Mean and standard deviation of data
#df_train.mean(), df_train.std(), df_test.mean(), df_test.std()

"""## Distributon properties"""


"""# Training the RBM

"""

# Convert dfs to torch format
X_train = torch.from_numpy(df_train).T.to(device).float()
X_test = torch.from_numpy(df_test).T.to(device).float()

"""### Using Pytorch code"""

myRBM = torch.load('model_symm_36_cells_sun_GRBM_9000_epochs_lr_0002_50_mcmc_steps_lr_div2_epoch300_3000_5000_3_4_data.pt', map_location=try_gpu())
number_of_epochs = myRBM.total_epochs
myRBM.device = try_gpu()

# half the learning rate
#myRBM.learning_rate = myRBM.learning_rate/2.

# ONLY If needed some extra epochs for training, run here selecting the number of extra epochs:
extra_epochs = 3000
number_of_epochs = myRBM.total_epochs + extra_epochs
myRBM.fit(X_train,X_test, epochs_max=extra_epochs)

"""#### Saving and loading a model"""

#@title Functions and location
# Saving the learned parameters
# Native pytorch format
torch.save(myRBM, 'model_symm_36_cells_sun_GRBM_12000_epochs_lr_0002_50_mcmc_steps_lr_div2_epoch300_3000_5000_3_4_data.pt')

plt.figure(figsize=(12,8))
plt.plot(np.arange(0,number_of_epochs, myRBM.Saving_interval), myRBM.energies_train, label='Train')
plt.plot(np.arange(0,number_of_epochs, myRBM.Saving_interval), myRBM.energies_test, label='Test')
plt.title('Mean energy per epoch')
plt.legend()
plt.xlabel('Epoch')
plt.show()

'''
plt.figure(figsize=(12,8))
plt.plot(np.arange(0,number_of_epochs, myRBM.Saving_interval), myRBM.log_likelihoods_train, label='Train')
plt.plot(np.arange(0,number_of_epochs, myRBM.Saving_interval), myRBM.log_likelihoods_test, label='Test')
plt.title('Mean Log-likelihood per epoch G-Rbm ')
plt.legend()
plt.xlabel('Epoch')
plt.show()

#@title Singular values full matrix { form-width: "300px" }
# Calculate the singular values of the full W matrix
singular_values_full_W = []
for matrix in myRBM.list_of_W_matrices[1:]:
    if myRBM.Symmetry_training:
        singular_values_full_W.append(torch.linalg.svd(myRBM._get_W_v_matrix(matrix))[1])
    if not myRBM.Symmetry_training:
        singular_values_full_W.append(torch.linalg.svd(matrix)[1])

plt.figure(figsize=(12,8))
n_sing_values_to_plot = 144
x_sing_vals = np.arange(len(singular_values_full_W))
x_sing_vals *= myRBM.Saving_interval
for svd_value in np.arange(n_sing_values_to_plot):
    plt.plot(x_sing_vals, [epoch[svd_value].item() for epoch in singular_values_full_W])
plt.title('First ' + str(n_sing_values_to_plot) + ' singular values of the full matrix per training epoch')
plt.xlabel('Training epoch')
plt.show()

# Visualizing the samples of persistent chain
x_plot = np.arange(0, days_solar_cycle, data_rate/24)
n_step_plots = 6
plot_int = np.random.randint(myRBM.X_persistent_chain.shape[1]-n_step_plots)
plt.figure(figsize=(10,6))
for plot, sample in enumerate(range(plot_int, plot_int+n_step_plots)):
    plt.plot(x_plot, myRBM.X_persistent_chain.t().cpu()[sample]+(plot*4))
plt.show()
'''
